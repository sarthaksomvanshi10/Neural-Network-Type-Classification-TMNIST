{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ASSIGNMENT - Neural Network Type Classification | TMNIST**"
      ],
      "metadata": {
        "id": "CD4DZTRXzWLm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2TzkAMfYnQp"
      },
      "source": [
        "**NEURAL NETWORK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEkFV89lrI3R"
      },
      "source": [
        "Training data is essential for neural networks to develop and enhance their accuracy over time. However, such algorithms for learning become effective tools in the fields of computing and machine learning once they are adjusted for accuracy, enabling us to quickly classify and cluster data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET USED** - https://www.kaggle.com/datasets/nimishmagre/tmnist-glyphs-1812-characters"
      ],
      "metadata": {
        "id": "ToTNKyMk2vlA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueaVdhxVsX5r"
      },
      "source": [
        " **TMNIST GLYPHS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUPzsm-6Rp1X"
      },
      "source": [
        "* A database of over 500,000 MNIST-style pictures made up of 1,812 unique glyphs and 2,990 font types is called **TMNIST (Typography MNIST) Glyphs.**\n",
        "* There is only one csv file in this repository.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZbI_PQSDY9"
      },
      "source": [
        "The csv file is organized as follows:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiuOTMnCSEnF"
      },
      "source": [
        "* Column headers in the first row are ['fontname', 'glyphname', 'label','1', '2',.....'784'].\n",
        "* 'Acme-Regular' and 'ZillaSlab-Bold' are only a couple of the font file names in the 'font_name' column.\n",
        "* The unicodedata name for the glyph, such as \"LATIN CAPITAL LETTER A\" and \"DEVANAGARI LETTER AA,\" is found in the \"glyph_name\" column.\n",
        "* The 'glyphname' column provides the names of both characters, joined together with a '+' symbol, for glyphs that are represented by more than one unicode character. For instance, \"\" has the glyphname \"DEVANAGARI SIGN ANUSVARA + DEVANAGARI LETTER A\"\n",
        "* The \"label\" column includes letters like \",\" \"E,\" or \".\"\n",
        "* The following 784 columns have the grayscale pixel values for the image of the corresponding character in the font-style 'font_name'.\n",
        "* Over 500,000 photos make up this dataset, which is a component of the Warhol.ai Computational Creativity and Congnitive Type projects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TlqmU5dNIaf"
      },
      "outputs": [],
      "source": [
        "# linear algebra\n",
        "import numpy as np\n",
        "# data processing\n",
        "import pandas as pd\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erh6lhpRY9Pm"
      },
      "source": [
        "**IMPORTING REQUIRED LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckFr9AmCNJtE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZl59rymN1lv"
      },
      "outputs": [],
      "source": [
        "#Reading a CSV File\n",
        "data = pd.read_csv(\"/Glyphs_TMNIST_updated.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Al0HtL0SZGLI",
        "outputId": "8d59923b-2e81-4d92-a617-19f72adaadf2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34faad0f-f3b1-45af-8f4f-33c3a6c06e07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>font_name</th>\n",
              "      <th>glyph_name</th>\n",
              "      <th>label</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABeeZee-Regular</td>\n",
              "      <td>LATIN CAPITAL LETTER A</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABeeZee-Regular</td>\n",
              "      <td>LATIN CAPITAL LETTER B</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABeeZee-Regular</td>\n",
              "      <td>LATIN CAPITAL LETTER C</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABeeZee-Regular</td>\n",
              "      <td>LATIN CAPITAL LETTER D</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABeeZee-Regular</td>\n",
              "      <td>LATIN CAPITAL LETTER E</td>\n",
              "      <td>E</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 787 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34faad0f-f3b1-45af-8f4f-33c3a6c06e07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34faad0f-f3b1-45af-8f4f-33c3a6c06e07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34faad0f-f3b1-45af-8f4f-33c3a6c06e07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         font_name              glyph_name label  1  2  3  4  5  6  7  ...  \\\n",
              "0  ABeeZee-Regular  LATIN CAPITAL LETTER A     A  0  0  0  0  0  0  0  ...   \n",
              "1  ABeeZee-Regular  LATIN CAPITAL LETTER B     B  0  0  0  0  0  0  0  ...   \n",
              "2  ABeeZee-Regular  LATIN CAPITAL LETTER C     C  0  0  0  0  0  0  0  ...   \n",
              "3  ABeeZee-Regular  LATIN CAPITAL LETTER D     D  0  0  0  0  0  0  0  ...   \n",
              "4  ABeeZee-Regular  LATIN CAPITAL LETTER E     E  0  0  0  0  0  0  0  ...   \n",
              "\n",
              "   775  776  777  778  779  780  781  782  783  784  \n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[5 rows x 787 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34RwIjQlOuHW",
        "outputId": "35375fc5-72a0-470f-8e6b-a83522639150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Shape of the Dataframe is: (107757, 787)\n",
            "Number of Samples: 107757\n"
          ]
        }
      ],
      "source": [
        "# printing the shape of a dataframe\n",
        "#the number of samples in the dataframe.\n",
        "print(f\"The Shape of the Dataframe is: {data.shape}\")\n",
        "print(f\"Number of Samples: {data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBBqQsc2eHO_"
      },
      "source": [
        "**CREATING A LIST OF ALPHANUMERIC CHARACTERS AND SYMBOLS, AND CALCULATING THE LENGTH OF THE LIST.**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC7eR13JPCzg",
        "outputId": "07aa556e-b9c6-4718-ad2c-7e0639eacf8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Alphanumeric and Symbols List\n",
        "\n",
        "symbs = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "         'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
        "         '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@','[',']','\\\\','^','_','`','{','}',\"|\",'~']\n",
        "\n",
        "len(symbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw_EDhBhd-Ga"
      },
      "source": [
        "The code provided creates a list of alphanumeric characters and symbols, and calculates the length of the list using the len() function. The list contains 62 alphanumeric characters (digits and uppercase/lowercase letters) and 32 symbols, resulting in a total of 94 characters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8D3P_yOPGZv"
      },
      "outputs": [],
      "source": [
        "M=list(range(len(symbs)))\n",
        "normal_mapping=dict(zip(symbs,M))\n",
        "reverse_mapping=dict(zip(M,symbs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZJWpy9KeTKp"
      },
      "source": [
        "\n",
        "The **normal_mapping** dictionary is created to establish a mapping between the characters in the symbs list and their corresponding indices in another list, denoted as M, which is generated using the range(len(symbs)) function. This list M essentially represents the indices of the characters in the symbs list. The zip() function is then utilized to combine the elements of the symbs list and the M list into pairs of characters and their corresponding indices. Finally, the dict() function is applied to these pairs to create a dictionary (normal_mapping) where each character from the symbs list is mapped to its respective index in the M list.\n",
        "\n",
        "The **reverse_mapping** dictionary serves the opposite purpose. It aims to map the indices present in the M list to their corresponding characters in the symbs list. Similar to the normal_mapping dictionary, the zip() function is employed to combine the elements of the M list (representing indices) and the symbs list into pairs of indices and characters. Subsequently, the dict() function is used to construct a dictionary (reverse_mapping) where each index from the M list is mapped to its corresponding character in the symbs list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB5WsGuEeX2m"
      },
      "source": [
        "Both normal_mapping and reverse_mapping can be used for character-to-index and index-to-character mappings, respectively, for the characters in the symbs list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4UVegFWehnA"
      },
      "source": [
        "**FILTERING A DATAFRAME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbuiHEVVPJRx"
      },
      "outputs": [],
      "source": [
        "data = data[data.label.isin(symbs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hYD-sP8hPMbR",
        "outputId": "393c46e4-9ef9-44e1-83d9-4c34d53864eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-94712439-314b-4b56-a21b-4215477357fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.082038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.076980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>60919.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94712439-314b-4b56-a21b-4215477357fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94712439-314b-4b56-a21b-4215477357fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94712439-314b-4b56-a21b-4215477357fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       count      mean       std  min  25%  50%  75%   max\n",
              "1    60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "2    60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "3    60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "4    60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "5    60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "..       ...       ...       ...  ...  ...  ...  ...   ...\n",
              "780  60919.0  0.000427  0.082038  0.0  0.0  0.0  0.0  19.0\n",
              "781  60919.0  0.000312  0.076980  0.0  0.0  0.0  0.0  19.0\n",
              "782  60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "783  60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "784  60919.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
              "\n",
              "[784 rows x 8 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvweQdYwPQ-t",
        "outputId": "607a9f14-a474-4d5a-b90e-f8ab48c44d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 60919 entries, 0 to 107656\n",
            "Data columns (total 787 columns):\n",
            " #    Column      Dtype  \n",
            "---   ------      -----  \n",
            " 0    font_name   object \n",
            " 1    glyph_name  object \n",
            " 2    label       object \n",
            " 3    1           int64  \n",
            " 4    2           int64  \n",
            " 5    3           int64  \n",
            " 6    4           int64  \n",
            " 7    5           int64  \n",
            " 8    6           int64  \n",
            " 9    7           int64  \n",
            " 10   8           int64  \n",
            " 11   9           int64  \n",
            " 12   10          int64  \n",
            " 13   11          int64  \n",
            " 14   12          int64  \n",
            " 15   13          int64  \n",
            " 16   14          int64  \n",
            " 17   15          int64  \n",
            " 18   16          int64  \n",
            " 19   17          int64  \n",
            " 20   18          int64  \n",
            " 21   19          int64  \n",
            " 22   20          int64  \n",
            " 23   21          int64  \n",
            " 24   22          int64  \n",
            " 25   23          int64  \n",
            " 26   24          int64  \n",
            " 27   25          int64  \n",
            " 28   26          int64  \n",
            " 29   27          int64  \n",
            " 30   28          int64  \n",
            " 31   29          int64  \n",
            " 32   30          int64  \n",
            " 33   31          int64  \n",
            " 34   32          int64  \n",
            " 35   33          int64  \n",
            " 36   34          int64  \n",
            " 37   35          int64  \n",
            " 38   36          int64  \n",
            " 39   37          int64  \n",
            " 40   38          int64  \n",
            " 41   39          int64  \n",
            " 42   40          int64  \n",
            " 43   41          int64  \n",
            " 44   42          int64  \n",
            " 45   43          int64  \n",
            " 46   44          int64  \n",
            " 47   45          int64  \n",
            " 48   46          int64  \n",
            " 49   47          int64  \n",
            " 50   48          int64  \n",
            " 51   49          int64  \n",
            " 52   50          int64  \n",
            " 53   51          int64  \n",
            " 54   52          int64  \n",
            " 55   53          int64  \n",
            " 56   54          int64  \n",
            " 57   55          int64  \n",
            " 58   56          int64  \n",
            " 59   57          int64  \n",
            " 60   58          int64  \n",
            " 61   59          int64  \n",
            " 62   60          int64  \n",
            " 63   61          int64  \n",
            " 64   62          int64  \n",
            " 65   63          int64  \n",
            " 66   64          int64  \n",
            " 67   65          int64  \n",
            " 68   66          int64  \n",
            " 69   67          int64  \n",
            " 70   68          int64  \n",
            " 71   69          int64  \n",
            " 72   70          int64  \n",
            " 73   71          int64  \n",
            " 74   72          int64  \n",
            " 75   73          int64  \n",
            " 76   74          int64  \n",
            " 77   75          int64  \n",
            " 78   76          int64  \n",
            " 79   77          int64  \n",
            " 80   78          int64  \n",
            " 81   79          int64  \n",
            " 82   80          int64  \n",
            " 83   81          int64  \n",
            " 84   82          int64  \n",
            " 85   83          int64  \n",
            " 86   84          int64  \n",
            " 87   85          int64  \n",
            " 88   86          int64  \n",
            " 89   87          int64  \n",
            " 90   88          int64  \n",
            " 91   89          int64  \n",
            " 92   90          int64  \n",
            " 93   91          int64  \n",
            " 94   92          int64  \n",
            " 95   93          int64  \n",
            " 96   94          int64  \n",
            " 97   95          int64  \n",
            " 98   96          int64  \n",
            " 99   97          int64  \n",
            " 100  98          int64  \n",
            " 101  99          int64  \n",
            " 102  100         int64  \n",
            " 103  101         int64  \n",
            " 104  102         int64  \n",
            " 105  103         int64  \n",
            " 106  104         int64  \n",
            " 107  105         int64  \n",
            " 108  106         int64  \n",
            " 109  107         int64  \n",
            " 110  108         int64  \n",
            " 111  109         int64  \n",
            " 112  110         int64  \n",
            " 113  111         int64  \n",
            " 114  112         int64  \n",
            " 115  113         int64  \n",
            " 116  114         int64  \n",
            " 117  115         int64  \n",
            " 118  116         int64  \n",
            " 119  117         int64  \n",
            " 120  118         int64  \n",
            " 121  119         int64  \n",
            " 122  120         int64  \n",
            " 123  121         int64  \n",
            " 124  122         int64  \n",
            " 125  123         int64  \n",
            " 126  124         int64  \n",
            " 127  125         int64  \n",
            " 128  126         int64  \n",
            " 129  127         int64  \n",
            " 130  128         int64  \n",
            " 131  129         int64  \n",
            " 132  130         int64  \n",
            " 133  131         int64  \n",
            " 134  132         int64  \n",
            " 135  133         int64  \n",
            " 136  134         int64  \n",
            " 137  135         int64  \n",
            " 138  136         int64  \n",
            " 139  137         int64  \n",
            " 140  138         int64  \n",
            " 141  139         int64  \n",
            " 142  140         int64  \n",
            " 143  141         int64  \n",
            " 144  142         int64  \n",
            " 145  143         int64  \n",
            " 146  144         int64  \n",
            " 147  145         int64  \n",
            " 148  146         int64  \n",
            " 149  147         int64  \n",
            " 150  148         int64  \n",
            " 151  149         int64  \n",
            " 152  150         int64  \n",
            " 153  151         int64  \n",
            " 154  152         int64  \n",
            " 155  153         int64  \n",
            " 156  154         int64  \n",
            " 157  155         int64  \n",
            " 158  156         int64  \n",
            " 159  157         int64  \n",
            " 160  158         int64  \n",
            " 161  159         int64  \n",
            " 162  160         int64  \n",
            " 163  161         int64  \n",
            " 164  162         int64  \n",
            " 165  163         int64  \n",
            " 166  164         int64  \n",
            " 167  165         int64  \n",
            " 168  166         int64  \n",
            " 169  167         int64  \n",
            " 170  168         int64  \n",
            " 171  169         int64  \n",
            " 172  170         int64  \n",
            " 173  171         int64  \n",
            " 174  172         int64  \n",
            " 175  173         int64  \n",
            " 176  174         int64  \n",
            " 177  175         int64  \n",
            " 178  176         int64  \n",
            " 179  177         int64  \n",
            " 180  178         int64  \n",
            " 181  179         int64  \n",
            " 182  180         int64  \n",
            " 183  181         int64  \n",
            " 184  182         int64  \n",
            " 185  183         int64  \n",
            " 186  184         int64  \n",
            " 187  185         int64  \n",
            " 188  186         int64  \n",
            " 189  187         int64  \n",
            " 190  188         int64  \n",
            " 191  189         int64  \n",
            " 192  190         int64  \n",
            " 193  191         int64  \n",
            " 194  192         int64  \n",
            " 195  193         int64  \n",
            " 196  194         int64  \n",
            " 197  195         int64  \n",
            " 198  196         int64  \n",
            " 199  197         int64  \n",
            " 200  198         int64  \n",
            " 201  199         int64  \n",
            " 202  200         int64  \n",
            " 203  201         int64  \n",
            " 204  202         int64  \n",
            " 205  203         int64  \n",
            " 206  204         int64  \n",
            " 207  205         int64  \n",
            " 208  206         int64  \n",
            " 209  207         int64  \n",
            " 210  208         int64  \n",
            " 211  209         int64  \n",
            " 212  210         int64  \n",
            " 213  211         int64  \n",
            " 214  212         int64  \n",
            " 215  213         int64  \n",
            " 216  214         int64  \n",
            " 217  215         int64  \n",
            " 218  216         int64  \n",
            " 219  217         int64  \n",
            " 220  218         int64  \n",
            " 221  219         int64  \n",
            " 222  220         int64  \n",
            " 223  221         int64  \n",
            " 224  222         int64  \n",
            " 225  223         int64  \n",
            " 226  224         int64  \n",
            " 227  225         int64  \n",
            " 228  226         int64  \n",
            " 229  227         int64  \n",
            " 230  228         int64  \n",
            " 231  229         int64  \n",
            " 232  230         int64  \n",
            " 233  231         int64  \n",
            " 234  232         int64  \n",
            " 235  233         int64  \n",
            " 236  234         int64  \n",
            " 237  235         int64  \n",
            " 238  236         int64  \n",
            " 239  237         int64  \n",
            " 240  238         int64  \n",
            " 241  239         int64  \n",
            " 242  240         int64  \n",
            " 243  241         int64  \n",
            " 244  242         int64  \n",
            " 245  243         int64  \n",
            " 246  244         int64  \n",
            " 247  245         int64  \n",
            " 248  246         int64  \n",
            " 249  247         int64  \n",
            " 250  248         int64  \n",
            " 251  249         int64  \n",
            " 252  250         int64  \n",
            " 253  251         int64  \n",
            " 254  252         int64  \n",
            " 255  253         int64  \n",
            " 256  254         int64  \n",
            " 257  255         int64  \n",
            " 258  256         int64  \n",
            " 259  257         int64  \n",
            " 260  258         int64  \n",
            " 261  259         int64  \n",
            " 262  260         int64  \n",
            " 263  261         int64  \n",
            " 264  262         int64  \n",
            " 265  263         int64  \n",
            " 266  264         int64  \n",
            " 267  265         int64  \n",
            " 268  266         int64  \n",
            " 269  267         int64  \n",
            " 270  268         int64  \n",
            " 271  269         int64  \n",
            " 272  270         int64  \n",
            " 273  271         int64  \n",
            " 274  272         int64  \n",
            " 275  273         int64  \n",
            " 276  274         int64  \n",
            " 277  275         int64  \n",
            " 278  276         int64  \n",
            " 279  277         int64  \n",
            " 280  278         int64  \n",
            " 281  279         int64  \n",
            " 282  280         int64  \n",
            " 283  281         int64  \n",
            " 284  282         int64  \n",
            " 285  283         int64  \n",
            " 286  284         int64  \n",
            " 287  285         int64  \n",
            " 288  286         int64  \n",
            " 289  287         int64  \n",
            " 290  288         int64  \n",
            " 291  289         int64  \n",
            " 292  290         int64  \n",
            " 293  291         int64  \n",
            " 294  292         int64  \n",
            " 295  293         int64  \n",
            " 296  294         int64  \n",
            " 297  295         int64  \n",
            " 298  296         int64  \n",
            " 299  297         int64  \n",
            " 300  298         int64  \n",
            " 301  299         int64  \n",
            " 302  300         int64  \n",
            " 303  301         int64  \n",
            " 304  302         int64  \n",
            " 305  303         int64  \n",
            " 306  304         int64  \n",
            " 307  305         int64  \n",
            " 308  306         int64  \n",
            " 309  307         int64  \n",
            " 310  308         int64  \n",
            " 311  309         int64  \n",
            " 312  310         int64  \n",
            " 313  311         int64  \n",
            " 314  312         int64  \n",
            " 315  313         int64  \n",
            " 316  314         int64  \n",
            " 317  315         int64  \n",
            " 318  316         int64  \n",
            " 319  317         int64  \n",
            " 320  318         int64  \n",
            " 321  319         int64  \n",
            " 322  320         int64  \n",
            " 323  321         int64  \n",
            " 324  322         int64  \n",
            " 325  323         int64  \n",
            " 326  324         int64  \n",
            " 327  325         int64  \n",
            " 328  326         int64  \n",
            " 329  327         int64  \n",
            " 330  328         int64  \n",
            " 331  329         int64  \n",
            " 332  330         int64  \n",
            " 333  331         int64  \n",
            " 334  332         int64  \n",
            " 335  333         int64  \n",
            " 336  334         int64  \n",
            " 337  335         int64  \n",
            " 338  336         int64  \n",
            " 339  337         int64  \n",
            " 340  338         int64  \n",
            " 341  339         int64  \n",
            " 342  340         int64  \n",
            " 343  341         int64  \n",
            " 344  342         int64  \n",
            " 345  343         int64  \n",
            " 346  344         int64  \n",
            " 347  345         float64\n",
            " 348  346         float64\n",
            " 349  347         float64\n",
            " 350  348         float64\n",
            " 351  349         float64\n",
            " 352  350         float64\n",
            " 353  351         float64\n",
            " 354  352         float64\n",
            " 355  353         float64\n",
            " 356  354         float64\n",
            " 357  355         float64\n",
            " 358  356         float64\n",
            " 359  357         float64\n",
            " 360  358         float64\n",
            " 361  359         float64\n",
            " 362  360         float64\n",
            " 363  361         float64\n",
            " 364  362         float64\n",
            " 365  363         float64\n",
            " 366  364         float64\n",
            " 367  365         float64\n",
            " 368  366         float64\n",
            " 369  367         float64\n",
            " 370  368         float64\n",
            " 371  369         float64\n",
            " 372  370         float64\n",
            " 373  371         float64\n",
            " 374  372         float64\n",
            " 375  373         float64\n",
            " 376  374         float64\n",
            " 377  375         float64\n",
            " 378  376         float64\n",
            " 379  377         float64\n",
            " 380  378         float64\n",
            " 381  379         float64\n",
            " 382  380         float64\n",
            " 383  381         float64\n",
            " 384  382         float64\n",
            " 385  383         float64\n",
            " 386  384         float64\n",
            " 387  385         float64\n",
            " 388  386         float64\n",
            " 389  387         float64\n",
            " 390  388         float64\n",
            " 391  389         float64\n",
            " 392  390         float64\n",
            " 393  391         float64\n",
            " 394  392         float64\n",
            " 395  393         float64\n",
            " 396  394         float64\n",
            " 397  395         float64\n",
            " 398  396         float64\n",
            " 399  397         float64\n",
            " 400  398         float64\n",
            " 401  399         float64\n",
            " 402  400         float64\n",
            " 403  401         float64\n",
            " 404  402         float64\n",
            " 405  403         float64\n",
            " 406  404         float64\n",
            " 407  405         float64\n",
            " 408  406         float64\n",
            " 409  407         float64\n",
            " 410  408         float64\n",
            " 411  409         float64\n",
            " 412  410         float64\n",
            " 413  411         float64\n",
            " 414  412         float64\n",
            " 415  413         float64\n",
            " 416  414         float64\n",
            " 417  415         float64\n",
            " 418  416         float64\n",
            " 419  417         float64\n",
            " 420  418         float64\n",
            " 421  419         float64\n",
            " 422  420         float64\n",
            " 423  421         float64\n",
            " 424  422         float64\n",
            " 425  423         float64\n",
            " 426  424         float64\n",
            " 427  425         float64\n",
            " 428  426         float64\n",
            " 429  427         float64\n",
            " 430  428         float64\n",
            " 431  429         float64\n",
            " 432  430         float64\n",
            " 433  431         float64\n",
            " 434  432         float64\n",
            " 435  433         float64\n",
            " 436  434         float64\n",
            " 437  435         float64\n",
            " 438  436         float64\n",
            " 439  437         float64\n",
            " 440  438         float64\n",
            " 441  439         float64\n",
            " 442  440         float64\n",
            " 443  441         float64\n",
            " 444  442         float64\n",
            " 445  443         float64\n",
            " 446  444         float64\n",
            " 447  445         float64\n",
            " 448  446         float64\n",
            " 449  447         float64\n",
            " 450  448         float64\n",
            " 451  449         float64\n",
            " 452  450         float64\n",
            " 453  451         float64\n",
            " 454  452         float64\n",
            " 455  453         float64\n",
            " 456  454         float64\n",
            " 457  455         float64\n",
            " 458  456         float64\n",
            " 459  457         float64\n",
            " 460  458         float64\n",
            " 461  459         float64\n",
            " 462  460         float64\n",
            " 463  461         float64\n",
            " 464  462         float64\n",
            " 465  463         float64\n",
            " 466  464         float64\n",
            " 467  465         float64\n",
            " 468  466         float64\n",
            " 469  467         float64\n",
            " 470  468         float64\n",
            " 471  469         float64\n",
            " 472  470         float64\n",
            " 473  471         float64\n",
            " 474  472         float64\n",
            " 475  473         float64\n",
            " 476  474         float64\n",
            " 477  475         float64\n",
            " 478  476         float64\n",
            " 479  477         float64\n",
            " 480  478         float64\n",
            " 481  479         float64\n",
            " 482  480         float64\n",
            " 483  481         float64\n",
            " 484  482         float64\n",
            " 485  483         float64\n",
            " 486  484         float64\n",
            " 487  485         float64\n",
            " 488  486         float64\n",
            " 489  487         float64\n",
            " 490  488         float64\n",
            " 491  489         float64\n",
            " 492  490         float64\n",
            " 493  491         float64\n",
            " 494  492         float64\n",
            " 495  493         float64\n",
            " 496  494         float64\n",
            " 497  495         float64\n",
            " 498  496         float64\n",
            " 499  497         float64\n",
            " 500  498         float64\n",
            " 501  499         float64\n",
            " 502  500         float64\n",
            " 503  501         float64\n",
            " 504  502         float64\n",
            " 505  503         float64\n",
            " 506  504         float64\n",
            " 507  505         float64\n",
            " 508  506         float64\n",
            " 509  507         float64\n",
            " 510  508         float64\n",
            " 511  509         float64\n",
            " 512  510         float64\n",
            " 513  511         float64\n",
            " 514  512         float64\n",
            " 515  513         float64\n",
            " 516  514         float64\n",
            " 517  515         float64\n",
            " 518  516         float64\n",
            " 519  517         float64\n",
            " 520  518         float64\n",
            " 521  519         float64\n",
            " 522  520         float64\n",
            " 523  521         float64\n",
            " 524  522         float64\n",
            " 525  523         float64\n",
            " 526  524         float64\n",
            " 527  525         float64\n",
            " 528  526         float64\n",
            " 529  527         float64\n",
            " 530  528         float64\n",
            " 531  529         float64\n",
            " 532  530         float64\n",
            " 533  531         float64\n",
            " 534  532         float64\n",
            " 535  533         float64\n",
            " 536  534         float64\n",
            " 537  535         float64\n",
            " 538  536         float64\n",
            " 539  537         float64\n",
            " 540  538         float64\n",
            " 541  539         float64\n",
            " 542  540         float64\n",
            " 543  541         float64\n",
            " 544  542         float64\n",
            " 545  543         float64\n",
            " 546  544         float64\n",
            " 547  545         float64\n",
            " 548  546         float64\n",
            " 549  547         float64\n",
            " 550  548         float64\n",
            " 551  549         float64\n",
            " 552  550         float64\n",
            " 553  551         float64\n",
            " 554  552         float64\n",
            " 555  553         float64\n",
            " 556  554         float64\n",
            " 557  555         float64\n",
            " 558  556         float64\n",
            " 559  557         float64\n",
            " 560  558         float64\n",
            " 561  559         float64\n",
            " 562  560         float64\n",
            " 563  561         float64\n",
            " 564  562         float64\n",
            " 565  563         float64\n",
            " 566  564         float64\n",
            " 567  565         float64\n",
            " 568  566         float64\n",
            " 569  567         float64\n",
            " 570  568         float64\n",
            " 571  569         float64\n",
            " 572  570         float64\n",
            " 573  571         float64\n",
            " 574  572         float64\n",
            " 575  573         float64\n",
            " 576  574         float64\n",
            " 577  575         float64\n",
            " 578  576         float64\n",
            " 579  577         float64\n",
            " 580  578         float64\n",
            " 581  579         float64\n",
            " 582  580         float64\n",
            " 583  581         float64\n",
            " 584  582         float64\n",
            " 585  583         float64\n",
            " 586  584         float64\n",
            " 587  585         float64\n",
            " 588  586         float64\n",
            " 589  587         float64\n",
            " 590  588         float64\n",
            " 591  589         float64\n",
            " 592  590         float64\n",
            " 593  591         float64\n",
            " 594  592         float64\n",
            " 595  593         float64\n",
            " 596  594         float64\n",
            " 597  595         float64\n",
            " 598  596         float64\n",
            " 599  597         float64\n",
            " 600  598         float64\n",
            " 601  599         float64\n",
            " 602  600         float64\n",
            " 603  601         float64\n",
            " 604  602         float64\n",
            " 605  603         float64\n",
            " 606  604         float64\n",
            " 607  605         float64\n",
            " 608  606         float64\n",
            " 609  607         float64\n",
            " 610  608         float64\n",
            " 611  609         float64\n",
            " 612  610         float64\n",
            " 613  611         float64\n",
            " 614  612         float64\n",
            " 615  613         float64\n",
            " 616  614         float64\n",
            " 617  615         float64\n",
            " 618  616         float64\n",
            " 619  617         float64\n",
            " 620  618         float64\n",
            " 621  619         float64\n",
            " 622  620         float64\n",
            " 623  621         float64\n",
            " 624  622         float64\n",
            " 625  623         float64\n",
            " 626  624         float64\n",
            " 627  625         float64\n",
            " 628  626         float64\n",
            " 629  627         float64\n",
            " 630  628         float64\n",
            " 631  629         float64\n",
            " 632  630         float64\n",
            " 633  631         float64\n",
            " 634  632         float64\n",
            " 635  633         float64\n",
            " 636  634         float64\n",
            " 637  635         float64\n",
            " 638  636         float64\n",
            " 639  637         float64\n",
            " 640  638         float64\n",
            " 641  639         float64\n",
            " 642  640         float64\n",
            " 643  641         float64\n",
            " 644  642         float64\n",
            " 645  643         float64\n",
            " 646  644         float64\n",
            " 647  645         float64\n",
            " 648  646         float64\n",
            " 649  647         float64\n",
            " 650  648         float64\n",
            " 651  649         float64\n",
            " 652  650         float64\n",
            " 653  651         float64\n",
            " 654  652         float64\n",
            " 655  653         float64\n",
            " 656  654         float64\n",
            " 657  655         float64\n",
            " 658  656         float64\n",
            " 659  657         float64\n",
            " 660  658         float64\n",
            " 661  659         float64\n",
            " 662  660         float64\n",
            " 663  661         float64\n",
            " 664  662         float64\n",
            " 665  663         float64\n",
            " 666  664         float64\n",
            " 667  665         float64\n",
            " 668  666         float64\n",
            " 669  667         float64\n",
            " 670  668         float64\n",
            " 671  669         float64\n",
            " 672  670         float64\n",
            " 673  671         float64\n",
            " 674  672         float64\n",
            " 675  673         float64\n",
            " 676  674         float64\n",
            " 677  675         float64\n",
            " 678  676         float64\n",
            " 679  677         float64\n",
            " 680  678         float64\n",
            " 681  679         float64\n",
            " 682  680         float64\n",
            " 683  681         float64\n",
            " 684  682         float64\n",
            " 685  683         float64\n",
            " 686  684         float64\n",
            " 687  685         float64\n",
            " 688  686         float64\n",
            " 689  687         float64\n",
            " 690  688         float64\n",
            " 691  689         float64\n",
            " 692  690         float64\n",
            " 693  691         float64\n",
            " 694  692         float64\n",
            " 695  693         float64\n",
            " 696  694         float64\n",
            " 697  695         float64\n",
            " 698  696         float64\n",
            " 699  697         float64\n",
            " 700  698         float64\n",
            " 701  699         float64\n",
            " 702  700         float64\n",
            " 703  701         float64\n",
            " 704  702         float64\n",
            " 705  703         float64\n",
            " 706  704         float64\n",
            " 707  705         float64\n",
            " 708  706         float64\n",
            " 709  707         float64\n",
            " 710  708         float64\n",
            " 711  709         float64\n",
            " 712  710         float64\n",
            " 713  711         float64\n",
            " 714  712         float64\n",
            " 715  713         float64\n",
            " 716  714         float64\n",
            " 717  715         float64\n",
            " 718  716         float64\n",
            " 719  717         float64\n",
            " 720  718         float64\n",
            " 721  719         float64\n",
            " 722  720         float64\n",
            " 723  721         float64\n",
            " 724  722         float64\n",
            " 725  723         float64\n",
            " 726  724         float64\n",
            " 727  725         float64\n",
            " 728  726         float64\n",
            " 729  727         float64\n",
            " 730  728         float64\n",
            " 731  729         float64\n",
            " 732  730         float64\n",
            " 733  731         float64\n",
            " 734  732         float64\n",
            " 735  733         float64\n",
            " 736  734         float64\n",
            " 737  735         float64\n",
            " 738  736         float64\n",
            " 739  737         float64\n",
            " 740  738         float64\n",
            " 741  739         float64\n",
            " 742  740         float64\n",
            " 743  741         float64\n",
            " 744  742         float64\n",
            " 745  743         float64\n",
            " 746  744         float64\n",
            " 747  745         float64\n",
            " 748  746         float64\n",
            " 749  747         float64\n",
            " 750  748         float64\n",
            " 751  749         float64\n",
            " 752  750         float64\n",
            " 753  751         float64\n",
            " 754  752         float64\n",
            " 755  753         float64\n",
            " 756  754         float64\n",
            " 757  755         float64\n",
            " 758  756         float64\n",
            " 759  757         float64\n",
            " 760  758         float64\n",
            " 761  759         float64\n",
            " 762  760         float64\n",
            " 763  761         float64\n",
            " 764  762         float64\n",
            " 765  763         float64\n",
            " 766  764         float64\n",
            " 767  765         float64\n",
            " 768  766         float64\n",
            " 769  767         float64\n",
            " 770  768         float64\n",
            " 771  769         float64\n",
            " 772  770         float64\n",
            " 773  771         float64\n",
            " 774  772         float64\n",
            " 775  773         float64\n",
            " 776  774         float64\n",
            " 777  775         float64\n",
            " 778  776         float64\n",
            " 779  777         float64\n",
            " 780  778         float64\n",
            " 781  779         float64\n",
            " 782  780         float64\n",
            " 783  781         float64\n",
            " 784  782         float64\n",
            " 785  783         float64\n",
            " 786  784         float64\n",
            "dtypes: float64(440), int64(344), object(3)\n",
            "memory usage: 366.2+ MB\n"
          ]
        }
      ],
      "source": [
        "# DataFrame feature's Datatype\n",
        "data.info(verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyoZlPm1e0wG"
      },
      "source": [
        "The code snippet offers a overview of the DataFrame, unveiling vital aspects such as data types, non-null value counts, and memory usage. This comprehensive information sheds light on the dataset's composition, aiding in understanding its structure, data types, and identifying potential missing values. Such insights are crucial for data exploration, enabling analysts to grasp the dataset's characteristics and make informed decisions regarding data manipulation and analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsNOP6Cye8cA"
      },
      "source": [
        "**PRINTING THE NUMBER OF UNIQUE FONTS AND UNIQUE CHARACTERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUaji9bKPe-Z",
        "outputId": "ea8ec4a1-9f0f-4bf7-f845-d13acb702e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique fonts present in the Dataset: 712\n",
            "Number of unique character present in the Dataset: 87\n"
          ]
        }
      ],
      "source": [
        "# Number of Fonts present in the Dataframe\n",
        "print(f\"Number of unique fonts present in the Dataset: {len(data.font_name.unique())}\")\n",
        "# Number of unique characters present in the Dataframe\n",
        "print(f\"Number of unique character present in the Dataset: {len(data.label.unique())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIo1rvM5fCNf"
      },
      "source": [
        "The code uses the unique() method from Pandas to get the unique values in the font_name and label columns of the DataFrame, and then calculates the length of these unique values using the len() function. Finally, the calculated counts are printed with appropriate messages using formatted strings.\n",
        "\n",
        "This code snippet may be part of a larger data analysis or data processing task, where the data DataFrame contains information about fonts and characters, and the goal is to determine the number of unique fonts and unique characters in the dataset. The results of these calculations will be displayed in the printed messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVc6ap1tPw1Q"
      },
      "outputs": [],
      "source": [
        "# Spliting the Labels and the features\n",
        "\n",
        "X = data.drop(columns=['font_name','glyph_name','label']).values\n",
        "y = data[['label']].values\n",
        "del data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRFI6DJqfTyl"
      },
      "source": [
        "The X array is created by dropping the columns 'font_name', 'glyph_name', and 'label' from the data DataFrame using the drop() method, and then extracting the values using the values attribute. This is likely done to extract the features or independent variables from the DataFrame, which will be used for further analysis or modeling.\n",
        "\n",
        "The y array is created by extracting only the 'label' column from the data DataFrame using double square brackets [['label']], which returns a DataFrame with a single column. The values attribute is then used to extract the values from this single column, resulting in a one-dimensional array containing the labels or dependent variable values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXrc-QG8fW6V"
      },
      "source": [
        "Finally, the data DataFrame is deleted using the del statement, which may be done to free up memory or remove unnecessary data from the memory after extracting the features and labels into separate arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VTL4jAqP3-f",
        "outputId": "e8082ce2-dc21-4766-b47d-fc620c4c66f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#converting the data type of 'x'\n",
        "X = X.astype('u1')\n",
        "X.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiYqME6HftWS"
      },
      "source": [
        "The astype('u1') function call is used to convert the data type of the X array to uint8, which is an unsigned integer type that can store values from 0 to 255. This type of conversion may be done for various reasons, such as reducing memory usage, ensuring compatibility with certain algorithms or libraries that require uint8 data, or converting data to a specific data type required for a particular analysis or task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4MFA0TCfuIz"
      },
      "source": [
        "After the data type conversion, the dtype attribute is used to check the data type of the X array, which should now be uint8. This can be useful for verifying that the data type conversion was successful and ensuring that the X array has the desired data type for subsequent analysis or modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DAtu9dFP98t",
        "outputId": "99623638-9620-4802-bf6a-8365a3e9649f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60919, 784), (60919, 1))"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking and displaying the shapes of the X and y\n",
        "X.shape, y.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l56xzcxJf8dY"
      },
      "source": [
        "The X.shape and y.shape are used to obtain the shapes (i.e., dimensions) of the X and y arrays, respectively. The shape attribute in NumPy or Pandas returns a tuple representing the dimensions of an array, with the first element representing the number of rows (samples) and the second element representing the number of columns (features or labels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k52xq7Gpf9MR"
      },
      "source": [
        "This code is likely used to verify the dimensions of the X and y arrays after they have been extracted from the data DataFrame and processed further, such as changing data types or performing additional data manipulation. The results of these operations can affect the shapes of the arrays, and checking the shapes can be useful for ensuring that the arrays have the expected dimensions before proceeding with further analysis or modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnX8xEzOgHz0"
      },
      "source": [
        "**VISUALIZING A SET OF IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "5nYl-VE4QBLz",
        "outputId": "dd1f4957-8ff8-446b-cb36-2756901170f6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x900 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_images = X.reshape(-1,28,28)\n",
        "fig,axs = plt.subplots(3,3,figsize=(9,9))\n",
        "for i in range(9):\n",
        "    r=i//3\n",
        "    c=i%3\n",
        "    axs[r][c].set_xticks([])\n",
        "    axs[r][c].set_yticks([])\n",
        "    axs[r][c].imshow(X_images[i])\n",
        "plt.show()\n",
        "del X_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g329SQ0KgL1W"
      },
      "source": [
        "The code starts by reshaping the X array into a 3D array with dimensions (-1, 28, 28), where -1 represents the number of images, and 28x28 represents the height and width of each image.\n",
        "\n",
        "Next, a 3x3 subplot grid is created using plt.subplots() function from Matplotlib with a figsize of (9,9), which specifies the size of the overall figure that will contain the subplots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_ZdVXLYgQ3c"
      },
      "source": [
        "Then, a loop iterates over the first 9 images in X_images, and for each image, a subplot is configured to have no x-axis and y-axis ticks using set_xticks([]) and set_yticks([]) methods. The image is displayed using imshow() method, which shows the image using a color map. Finally, the plt.show() function is called to display the entire figure with the subplots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3lLO5yYgRvb"
      },
      "source": [
        "After the visualization is displayed, the X_images array is deleted using the del statement, which may be done to free up memory or remove unnecessary data from the memory after the images have been visualized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4X5QyUHQFKK"
      },
      "outputs": [],
      "source": [
        "#performing a train-test split on X and y\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "y_train = y_train.reshape((-1,))\n",
        "y_test = y_test.reshape((-1,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRSKxp4rgjPW"
      },
      "source": [
        "The test_size parameter is set to 0.1, which indicates that 10% of the data will be used for testing, and the remaining 90% will be used for training. The resulting X_train, X_test, y_train, and y_test arrays represent the training and testing sets for the features and labels, respectively.\n",
        "\n",
        "After the split, the y_train and y_test arrays are reshaped using the reshape() method with -1 as the argument, which is used to infer the correct shape for the array based on the size of the array and the remaining dimensions. This may be done to ensure that the labels have the correct shape for further processing or modeling, as some machine learning algorithms may require labels to be in a specific shape or format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrRYxf-DQI5Q",
        "outputId": "7bbf4967-9fd9-42d0-db32-14ef9c4d58c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((54827,), (6092,))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape\n",
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps3RxR6Cg-F2"
      },
      "source": [
        "**LABELBINARIZER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfHf1WOaQO8z",
        "outputId": "0323236f-704d-4b55-f81e-1765c9e1919f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels dimension:\n",
            "(54827,)\n",
            "Test labels dimension:\n",
            "(6092,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_train_label = lb.fit_transform(y_train)\n",
        "y_test_label = lb.transform(y_test)\n",
        "print('Train labels dimension:');print(y_train.shape)\n",
        "print('Test labels dimension:');print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS1nvAqzhCKz"
      },
      "source": [
        "\n",
        "The **LabelBinarizer** class is a frequently utilized tool in machine learning for converting categorical labels into binary representations, often employed for tasks like one-hot encoding. In the provided code snippet, an instance of LabelBinarizer, denoted as lb, is instantiated. This instance is then utilized to both fit and transform the y_train array, converting its categorical labels into binary representations. The resulting binary labels are stored in the y_train_label variable. Similarly, the same lb instance is employed to transform the y_test array into binary labels, subsequently stored in the y_test_label variable. This process enables the conversion of categorical labels into a format suitable for various machine learning algorithms, facilitating the training and evaluation of models on categorical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTJHKNJwQSmQ"
      },
      "outputs": [],
      "source": [
        "# Normalizing the Dataset for the Neural Network\n",
        "X_train, X_test = np.true_divide(X_train, 255), np.true_divide(X_test, 255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFQbjLUjhNjl"
      },
      "source": [
        "The **np.true_divide()** function from the NumPy library plays a crucial role in the preprocessing of pixel data within the X_train and X_test arrays. Specifically, this function is employed to divide each pixel value by 255, which represents the maximum intensity value in an 8-bit grayscale image. By doing so, the operation effectively scales the pixel values from their original range of [0, 255] to a normalized range of [0, 1]. Normalizing pixel values in this manner is a common practice in image processing and machine learning tasks, as it ensures that all pixel intensities lie within the same range, thereby facilitating model convergence and enhancing the stability of training algorithms. This normalization step is particularly beneficial when working with neural networks and other machine learning models that are sensitive to the scale of input data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH_ygw-mhSaQ"
      },
      "source": [
        "Normalizing the pixel values is a common preprocessing step in machine learning, especially for deep learning models like neural networks, as it helps to bring the pixel values to a similar scale and prevents any single feature from dominating the others. Normalization can also help with improving the convergence and performance of the neural network during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCxi-Z-sQX2J"
      },
      "outputs": [],
      "source": [
        "# Reshape X_train and X_test for CNN\n",
        "X_train = X_train.reshape(-1,28,28,1).astype('float32')\n",
        "X_test = X_test.reshape(-1,28,28,1).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQMQxBX1hhUh"
      },
      "source": [
        "**CONCOLUTIONAL NEURAL NETWORK (CNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVf2sWKdYuNR"
      },
      "source": [
        "\n",
        "In a convolutional neural network (CNN), which can consist of numerous layers, ranging from tens to even hundreds, each layer is trained to recognize distinct aspects of an image. The output of each layer, often referred to as a convolved feature map, serves as the input to the subsequent layer after filters are applied to each training image at different resolutions. These filters initially detect relatively simple features such as brightness and edges, gradually progressing to more complex patterns until they eventually identify specific objects within the image. Through this hierarchical arrangement of layers and filters, CNNs effectively extract and learn increasingly intricate features from input images, enabling them to achieve high levels of accuracy in tasks such as image classification and object recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq3sCSs3Yy9p"
      },
      "source": [
        "# Architecture of a Convolutional Neural Network (CNN)\n",
        "![CNN Architecture](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*qsbsCVyu376kqdnNcdxmmw.png)\n",
        "\n",
        "Using the above diagram, we know that there are:\n",
        "\n",
        "1. Convolution layer where convolution happens.\n",
        "2. Pooling layer where the pooling process happens\n",
        "3. Normalization usually with the use of ReLu\n",
        "4. Fully Connected Layers\n",
        "\n",
        "\n",
        "The **Convolutional Layer (CONV)** stands as the fundamental building block within a CNN, tasked with executing convolutional operations crucial for feature extraction. At the heart of this layer lies the Kernel or Filter, responsible for performing convolution operations on the input image. As the kernel traverses the image, it applies horizontal and vertical changes dictated by the specified stride rate until the entire image is scanned. Although the kernel is typically smaller in size compared to the input image, it possesses depth. In cases where the input image comprises three channels (RGB), the kernel's height and width remain relatively modest, while its depth spans across all three channels, enabling it to capture features across the entire image spectrum.\n",
        "\n",
        "![](https://www.interviewbit.com/blog/wp-content/uploads/2022/06/Convolutional-Layer-1536x558.png)\n",
        "\n",
        "\n",
        "The **Pooling Layer (POOL)**serves a crucial role in CNNs by reducing dimensionality, thereby alleviating the computational burden associated with processing large volumes of data. This layer encompasses two main types of pooling: Maximum and Average pooling. In Maximum pooling, the layer returns the highest value from the region of the image covered by the kernel, effectively highlighting the most salient features within that region. Conversely, Average pooling computes the average of all values within the kernel-covered area, providing a smoothed representation of the underlying features. By selectively retaining essential information while discarding redundant details, the Pooling Layer facilitates efficient data processing and enhances the CNN's ability to extract meaningful features from input images.\n",
        "\n",
        "![](https://www.interviewbit.com/blog/wp-content/uploads/2022/06/Pooling-Layer-1536x719.png)\n",
        "\n",
        "**Dropout Layers:** A Dropout layer is a mask that eliminates some neurons' contributions to the subsequent layer while leaving all others unaltered. A Dropout layer can be applied to the input vector to cancel out part of its attributes; however, it can also be applied to a hidden layer to cancel out some hidden neurons. Dropout layers are essential in CNN training because they avoid overfitting of the training data. The first batch of training data has a disproportionately strong impact on learning if they are not present. As a result, learning of features found only in later samples or batches would be avoided.\n",
        "\n",
        "**Fully Connected Layer (FC**): The fully connected layer (FC) works with a flattened input, which means that each input is coupled to every neuron. After that, the flattened vector is sent via a few additional FC layers, where the mathematical functional operations are normally performed. The classification procedure gets started at this point. FC layers are frequently found near the end of CNN architectures if they are present.\n",
        "\n",
        "**Activation Function:** The activation function of the final fully connected layer is typically different from the others. The proper activation function must be chosen for each activity. The softmax function is an activation function used in the multiclass classification problem. It normalizes output real values from the last fully connected layer to target class probabilities, where each value ranges from 0 to 1 and all values add up to 1.\n",
        "\n",
        "Following is a table of the main activation functions with their graphs and formulas.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/1*p_hyqAtyI8pbt2kEl6siOQ.png)\n",
        "\n",
        "Here's a summary of above table:\n",
        "\n",
        "1. The table presents various activation functions used in neural networks, including their mathematical equations, plots, and derivatives.\n",
        "2. Linear functions like Identity and Binary Step have simple equations and derivatives, while non-linear functions like Logistic, TanH, and ELU have more complex, curved shapes and derivatives.\n",
        "3. Rectified Linear Units (ReLU and its variants) are piecewise linear functions that output the input directly for non-negative values and either 0 or a small value for negative inputs.\n",
        "4. The derivatives of the activation functions are crucial for backpropagation and training neural networks using gradient-based optimization methods.\n",
        "5. The choice of activation function depends on the specific problem and model architecture, as different functions have different properties and trade-offs in terms of non-linearity, sparsity, and smoothness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8NU3vx4ZPrJ"
      },
      "source": [
        "*  These layers carry out operations on the data in order to discover characteristics unique to the data. Convolution, activation or ReLU, and pooling are three of the most used layers.\n",
        "*  Convolution runs a series of convolutional filters through the input images, activating different aspects of the images with each filter.\n",
        "*  Rectified linear unit (ReLU), which maintains positive values while translating negative values to zero, enables quicker and more efficient training.\n",
        "*  Due to the fact that only the activated features are carried over to the following layer, this is frequently referred to as activation.\n",
        "By conducting nonlinear downsampling on the output, pooling reduces the number of parameters the network needs to learn.\n",
        "*  Over tens or hundreds of layers, these procedures are repeated, and each layer learns to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lu3b0-eWQa9C"
      },
      "outputs": [],
      "source": [
        "#Defining and compiling a convolutional neural network\n",
        "cnnmodel = Sequential()\n",
        "cnnmodel.add(Conv2D(32,(4,4),input_shape = (28,28,1),activation = 'relu'))\n",
        "cnnmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnnmodel.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "cnnmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnnmodel.add(Dropout(0.2))\n",
        "cnnmodel.add(Flatten())\n",
        "cnnmodel.add(Dense(128,activation='relu'))\n",
        "cnnmodel.add(Dense(y_train_label.shape[1], activation='softmax'))\n",
        "cnnmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmOOX-CUhkeF"
      },
      "source": [
        "Defines and compiles a CNN model for image classification, with the architecture consisting of convolutional, pooling, dropout, and fully connected layers, and using the Adam optimizer with categorical cross-entropy loss for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEGEeNPlQeWO",
        "outputId": "4cca9a95-a372-44eb-fbc6-88fc3dff64f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 25, 25, 32)        544       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 87)                11223     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,191\n",
            "Trainable params: 235,191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnnmodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS13iSPKhzd0"
      },
      "source": [
        "The purpose of this code snippet is to invoke the summary() method on a pre-defined CNN model (cnnmodel), which in turn presents a concise overview of the model's architecture. This summary encapsulates crucial details such as the number of parameters within each layer, the input and output shapes of every layer, and the overall count of parameters across the entire model. By offering insights into the model's structure and size, this summary aids in comprehending the complexity and capacity of the CNN model. Additionally, it assists in identifying potential issues like overfitting or underfitting, thereby facilitating effective model evaluation and optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gfX2V7qiE2-"
      },
      "source": [
        "**FITTING THE PRE-DEFINED CNN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkaSGi5wQhi_",
        "outputId": "2bebfca1-8c04-4f2a-ca3f-7b493002bd7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1401/1401 [==============================] - 136s 95ms/step - loss: 0.6738 - accuracy: 0.8152 - val_loss: 0.3873 - val_accuracy: 0.8797\n",
            "Epoch 2/50\n",
            "1401/1401 [==============================] - 132s 94ms/step - loss: 0.3113 - accuracy: 0.9015 - val_loss: 0.2625 - val_accuracy: 0.9179\n",
            "Epoch 3/50\n",
            "1401/1401 [==============================] - 129s 92ms/step - loss: 0.2403 - accuracy: 0.9242 - val_loss: 0.2273 - val_accuracy: 0.9294\n",
            "Epoch 4/50\n",
            "1401/1401 [==============================] - 131s 93ms/step - loss: 0.2057 - accuracy: 0.9340 - val_loss: 0.2029 - val_accuracy: 0.9376\n",
            "Epoch 5/50\n",
            "1401/1401 [==============================] - 130s 93ms/step - loss: 0.1808 - accuracy: 0.9406 - val_loss: 0.1884 - val_accuracy: 0.9423\n",
            "Epoch 6/50\n",
            "1401/1401 [==============================] - 131s 93ms/step - loss: 0.1633 - accuracy: 0.9457 - val_loss: 0.1784 - val_accuracy: 0.9438\n",
            "Epoch 7/50\n",
            "1401/1401 [==============================] - 129s 92ms/step - loss: 0.1494 - accuracy: 0.9490 - val_loss: 0.1794 - val_accuracy: 0.9453\n",
            "Epoch 8/50\n",
            "1401/1401 [==============================] - 129s 92ms/step - loss: 0.1394 - accuracy: 0.9513 - val_loss: 0.1751 - val_accuracy: 0.9472\n",
            "Epoch 9/50\n",
            "1401/1401 [==============================] - 130s 93ms/step - loss: 0.1277 - accuracy: 0.9557 - val_loss: 0.1689 - val_accuracy: 0.9479\n",
            "Epoch 10/50\n",
            "1401/1401 [==============================] - 130s 93ms/step - loss: 0.1207 - accuracy: 0.9576 - val_loss: 0.1716 - val_accuracy: 0.9496\n",
            "Epoch 11/50\n",
            "1401/1401 [==============================] - 131s 93ms/step - loss: 0.1132 - accuracy: 0.9601 - val_loss: 0.1777 - val_accuracy: 0.9452\n",
            "Epoch 12/50\n",
            "1401/1401 [==============================] - 130s 93ms/step - loss: 0.1066 - accuracy: 0.9618 - val_loss: 0.1660 - val_accuracy: 0.9504\n",
            "Epoch 13/50\n",
            "1401/1401 [==============================] - 131s 94ms/step - loss: 0.1022 - accuracy: 0.9633 - val_loss: 0.1761 - val_accuracy: 0.9488\n",
            "Epoch 14/50\n",
            "1401/1401 [==============================] - 131s 94ms/step - loss: 0.0963 - accuracy: 0.9653 - val_loss: 0.1673 - val_accuracy: 0.9511\n",
            "Epoch 15/50\n",
            "1401/1401 [==============================] - 132s 94ms/step - loss: 0.0910 - accuracy: 0.9667 - val_loss: 0.1903 - val_accuracy: 0.9466\n",
            "Epoch 16/50\n",
            "1401/1401 [==============================] - 129s 92ms/step - loss: 0.0890 - accuracy: 0.9674 - val_loss: 0.1677 - val_accuracy: 0.9528\n",
            "Epoch 17/50\n",
            "1401/1401 [==============================] - 130s 93ms/step - loss: 0.0859 - accuracy: 0.9681 - val_loss: 0.1760 - val_accuracy: 0.9519\n",
            "Epoch 18/50\n",
            "1401/1401 [==============================] - 128s 91ms/step - loss: 0.0816 - accuracy: 0.9698 - val_loss: 0.1776 - val_accuracy: 0.9527\n",
            "Epoch 19/50\n",
            "1401/1401 [==============================] - 131s 94ms/step - loss: 0.0797 - accuracy: 0.9704 - val_loss: 0.1743 - val_accuracy: 0.9533\n",
            "Epoch 20/50\n",
            "1401/1401 [==============================] - 129s 92ms/step - loss: 0.0764 - accuracy: 0.9711 - val_loss: 0.1809 - val_accuracy: 0.9544\n",
            "Epoch 21/50\n",
            "1401/1401 [==============================] - 128s 91ms/step - loss: 0.0753 - accuracy: 0.9715 - val_loss: 0.1811 - val_accuracy: 0.9526\n",
            "Epoch 22/50\n",
            "1401/1401 [==============================] - 130s 93ms/step - loss: 0.0704 - accuracy: 0.9734 - val_loss: 0.1851 - val_accuracy: 0.9531\n",
            "Epoch 23/50\n",
            "1401/1401 [==============================] - 125s 89ms/step - loss: 0.0698 - accuracy: 0.9735 - val_loss: 0.1989 - val_accuracy: 0.9493\n",
            "Epoch 24/50\n",
            "1401/1401 [==============================] - 119s 85ms/step - loss: 0.0692 - accuracy: 0.9736 - val_loss: 0.1866 - val_accuracy: 0.9541\n",
            "Epoch 25/50\n",
            "1401/1401 [==============================] - 119s 85ms/step - loss: 0.0670 - accuracy: 0.9749 - val_loss: 0.1966 - val_accuracy: 0.9543\n",
            "Epoch 26/50\n",
            "1401/1401 [==============================] - 120s 86ms/step - loss: 0.0649 - accuracy: 0.9754 - val_loss: 0.1958 - val_accuracy: 0.9535\n",
            "Epoch 27/50\n",
            "1401/1401 [==============================] - 119s 85ms/step - loss: 0.0626 - accuracy: 0.9762 - val_loss: 0.1965 - val_accuracy: 0.9525\n",
            "Epoch 28/50\n",
            "1401/1401 [==============================] - 120s 85ms/step - loss: 0.0619 - accuracy: 0.9764 - val_loss: 0.1957 - val_accuracy: 0.9535\n",
            "Epoch 29/50\n",
            "1401/1401 [==============================] - 120s 86ms/step - loss: 0.0609 - accuracy: 0.9770 - val_loss: 0.2003 - val_accuracy: 0.9539\n",
            "Epoch 30/50\n",
            "1401/1401 [==============================] - 118s 84ms/step - loss: 0.0594 - accuracy: 0.9772 - val_loss: 0.2028 - val_accuracy: 0.9537\n",
            "Epoch 31/50\n",
            "1401/1401 [==============================] - 120s 86ms/step - loss: 0.0591 - accuracy: 0.9778 - val_loss: 0.2011 - val_accuracy: 0.9537\n",
            "Epoch 32/50\n",
            "1401/1401 [==============================] - 118s 84ms/step - loss: 0.0567 - accuracy: 0.9784 - val_loss: 0.2122 - val_accuracy: 0.9531\n",
            "Epoch 33/50\n",
            "1401/1401 [==============================] - 120s 85ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 0.2155 - val_accuracy: 0.9531\n",
            "Epoch 34/50\n",
            "1401/1401 [==============================] - 119s 85ms/step - loss: 0.0559 - accuracy: 0.9790 - val_loss: 0.2122 - val_accuracy: 0.9542\n",
            "Epoch 35/50\n",
            "1401/1401 [==============================] - 120s 85ms/step - loss: 0.0541 - accuracy: 0.9791 - val_loss: 0.2209 - val_accuracy: 0.9528\n",
            "Epoch 36/50\n",
            "1401/1401 [==============================] - 118s 84ms/step - loss: 0.0542 - accuracy: 0.9792 - val_loss: 0.2107 - val_accuracy: 0.9539\n",
            "Epoch 37/50\n",
            "1401/1401 [==============================] - 119s 85ms/step - loss: 0.0536 - accuracy: 0.9795 - val_loss: 0.2312 - val_accuracy: 0.9529\n",
            "Epoch 38/50\n",
            "1401/1401 [==============================] - 118s 85ms/step - loss: 0.0510 - accuracy: 0.9805 - val_loss: 0.2197 - val_accuracy: 0.9548\n",
            "Epoch 39/50\n",
            "1401/1401 [==============================] - 118s 85ms/step - loss: 0.0510 - accuracy: 0.9804 - val_loss: 0.2199 - val_accuracy: 0.9560\n",
            "Epoch 40/50\n",
            "1401/1401 [==============================] - 118s 85ms/step - loss: 0.0492 - accuracy: 0.9810 - val_loss: 0.2344 - val_accuracy: 0.9554\n",
            "Epoch 41/50\n",
            "1401/1401 [==============================] - 120s 85ms/step - loss: 0.0507 - accuracy: 0.9806 - val_loss: 0.2371 - val_accuracy: 0.9553\n",
            "Epoch 42/50\n",
            "1401/1401 [==============================] - 118s 84ms/step - loss: 0.0489 - accuracy: 0.9814 - val_loss: 0.2219 - val_accuracy: 0.9542\n",
            "Epoch 43/50\n",
            "1401/1401 [==============================] - 121s 86ms/step - loss: 0.0482 - accuracy: 0.9815 - val_loss: 0.2272 - val_accuracy: 0.9540\n",
            "Epoch 44/50\n",
            " 338/1401 [======>.......................] - ETA: 1:28 - loss: 0.0458 - accuracy: 0.9826"
          ]
        }
      ],
      "source": [
        "result = cnnmodel.fit(X_train, y_train_label, validation_split=0.1, epochs=50, batch_size=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLoF3iJliLe4"
      },
      "source": [
        "The model undergoes training with a validation split parameter set to 0.1, signifying that 10% of the training data is allocated for validation purposes during the training phase. The training process spans across 50 epochs, each comprising iterations over batches of 100 data samples. The training progress is visually monitored as the verbose mode is enabled, set to 1, which entails that progress updates along with loss and accuracy metrics will be displayed during training. The result variable is anticipated to retain the training metrics and statistical data, facilitating in-depth analysis and evaluation of the model's performance post-training. This comprehensive approach to training configuration and monitoring allows for thorough assessment and refinement of the CNN model's efficacy and generalization capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy2bI0h_iTBF"
      },
      "source": [
        "**EVALUATING THE PRE-TRAINED CNN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwNGk4WuQntw",
        "outputId": "54857e7c-7519-4740-8e9a-10744010267f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "191/191 [==============================] - 2s 9ms/step - loss: 0.2893 - accuracy: 0.9473\n",
            "Test results - Accuracy: 0.9473079442977905%\n"
          ]
        }
      ],
      "source": [
        "test_results = cnnmodel.evaluate(X_test, y_test_label, verbose=1)\n",
        "print(f'Test results - Accuracy: {test_results[1]}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDzfV13LiYNW"
      },
      "source": [
        "The test results, including the accuracy of the model, are stored in the test_results variable. The accuracy of the model on the test data is then printed using print(). This code is likely used to assess the performance of the trained model on unseen data and obtain the accuracy as an evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "99QNI35qQwjk",
        "outputId": "6ca50b57-5854-4cf3-9d29-f4ef1fdaaa75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#visualizing the training progress\n",
        "#performance of the CNN model during training.\n",
        "his = pd.DataFrame(result.history)\n",
        "his.loc[:, ['accuracy', 'val_accuracy']].plot()\n",
        "his.loc[:, ['loss', 'val_loss']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb_0RRgQikWm"
      },
      "source": [
        "The training metrics, comprising accuracy and loss values, are stored within a Pandas DataFrame accessed via result.history. These metrics are then visualized using Matplotlib, where one plot displays both training and validation accuracy, while another plot showcases training and validation loss. By plotting these metrics against epochs, the code enables a visual examination of the model's performance evolution, aiding in understanding the training progress, convergence behavior, and detecting any indications of overfitting or underfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcEhOuGqT3vh"
      },
      "source": [
        "**CONCLUSION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK1BZ1wIj5hy"
      },
      "source": [
        "Achieving a 95% accuracy after training a convolutional neural network (CNN) model on the dataset is indicative of its effectiveness in learning and recognizing patterns within the data. The CNN architecture, known for its ability to capture spatial hierarchies in images, likely played a crucial role in this performance boost. By employing convolutional layers to extract features and pooling layers to reduce dimensionality, the model can effectively learn relevant representations from the input images. Additionally, techniques such as dropout regularization may have helped prevent overfitting, contributing to the model's generalization performance. Overall, the significant improvement in accuracy underscores the CNN's capability to discern intricate patterns and highlights its suitability for image classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E-JNLxmvI_n"
      },
      "source": [
        "**CITATIONS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uChaM996vLcA"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*   https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html\n",
        "* https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939\n",
        "* https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
        "* https://www.geeksforgeeks.org/cnn-image-data-pre-processing-with-generators/\n",
        "* https://en.wikipedia.org/wiki/Neural_network\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNWc-7ukndwP"
      },
      "source": [
        "**LICENSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0PvXSpBnfQn"
      },
      "source": [
        "2024 Copyright Sarthak Shailesh Somvanshi\n",
        "\n",
        "The right to deal in the software without restriction, including without limitation the right to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software, is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), subject to the following requirements:\n",
        "\n",
        "All copies or substantial parts of the Software must carry the aforementioned copyright notice and this permission notice.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}